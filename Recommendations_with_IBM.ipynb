{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTbq9mm-vlKz"
   },
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "In this notebook, you will be putting your recommendation skills to use on real data from the IBM Watson Studio platform.\n",
    "\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](Need to update this).  **Please save regularly.**\n",
    "\n",
    "By following the table of contents, you will build out a number of different methods for making recommendations that can be used for different situations.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "At the end of the notebook, you will find directions for how to submit your work.  Let's get started by importing the necessary libraries and reading in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "YjGLamcBvlK1",
    "outputId": "68e002dc-f275-4536-ce29-b89b4a6db4ea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_content\",\n  \"rows\": 1056,\n  \"fields\": [\n    {\n      \"column\": \"doc_body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1036,\n        \"samples\": [\n          \"* DATA WAREHOUSING FEATURES, IMPROVEMENTS, AND UPDATES: INTRODUCING THE NEWDASHDBBy Alan HoffmanDecember 19, 2014INTRODUCING THE NEW DASHDBToday we\\u2019re excited to announce that the Cloudant/dashDB integration isofficially out of beta and into General Availability. For those that don\\u2019t know,IBM dashDB is a cloud-based data warehouse with built-in analytics tailored tohelp ensure you\\u2019re making the most of your data. dashDB is accessible right inthe Cloudant dashboard by way of the Warehousing tab.We have made a number of upgrades, performance improvements, and bugfixes inthis release. Our initial dashDB blog post still gives a good overview of dashDB\\u2019s integration with Cloudant and serves asa helpful getting started guide.Here are some of the highlights from this release: 1. The limit to the warehouse size has been increased from 1 GB to 10 GB    (compressed,) which translates into roughly 30 GB of JSON but your mileage    may vary based on compression. That\\u2019s more than enough to get meaningful    insight from your Cloudant data. Please note that you are still entitled to    one warehouse per Cloudant account 2.  3. Incremental updates are here! Your warehouses will be automatically updated    as you add new data to the underlying database and you will no longer need    to rescan to include new data. 4.  5. Improved performance. Initial testing shows a 20x improvement in data    transfer and schema discovery. You\\u2019ll be able to move more data, much    faster, to your dashDB instance 6.  7. Finally, we have improved our integration with IBM Bluemix so warehouses you    create in Cloudant will be accessible from your Bluemix console. Because of    this, you will be asked for a Bluemix id and password when you create or    delete a warehouse. If you do not have a Bluemix id, you can get one hereWith great power comes great responsibility (meaning billing of course.)Customers that create warehouses will be expected (after a 30 day free trial) toprovide credit card info to Bluemix to ensure continued use of the service.(Users that exceed the free limit on dashDB warehouses (1 GB compressed) will berequired to enter a credit card so they can be billed.)We are by no means done with our work on dashDB, the Schema Discovery Process(SDP), or the Cloudant integration. This is simply the next step in ourcontinued evolution. We\\u2019ve got of an exciting plans for 2015. We would love to hear your feedback about how we can improve the service for you so please don\\u2019t hesitate to reachout .Please enable JavaScript to view the comments powered by Disqus.SIGN UP FOR UPDATES!RECENT POSTS * Data Privacy and Governance Update * Cloudant Warehousing: New features and improvements * Announcing ISO 27001 Compliance for Cloudant, dashDB and BigInsights! * Understanding Mango View-Based Indexes vs. Search-Based Indexes * Introducing Monitoring Plugins for IBM Cloudant LocalBlog archive Follow @cloudantPRODUCT * Why DBaaS? * Features * Pricing * DBaaS ComparisonDOCS * Getting Started * API Reference * Libraries * GuidesFOR DEVELOPERS * FAQ * Sample AppsRESOURCES * Blog * Case Studies * Data Sheets * Training * Webinars * Whitepapers * Videos * EventsCOMPANY * About Us * Contact UsNEWS * In the Press * Press Releases * Awards * Terms Of Use * | * Privacy * | * \\u00a9IBM Corporation 2016\",\n          \"Study Group Deep Learning Curriculum Blog Newsletter ArchiveTENSORFLOW QUICK TIPS\\r\\nby Malte Baumann on February 19, 2017\\r\\n\\r\\n\\r\\n\\r\\nTENSORFLOW WAS THE NEW KID ON THE BLOCK WHEN IT WAS INTRODUCED IN 2015 AND HAS\\r\\nBECOME THE MOST USED DEEP LEARNING FRAMEWORK LAST YEAR. I JUMPED ON THE TRAIN A\\r\\nFEW MONTHS AFTER THE FIRST RELEASE AND BEGAN MY JOURNEY INTO DEEP LEARNING\\r\\nDURING MY MASTER'S THESIS. IT TOOK A WHILE TO GET USED TO THE COMPUTATION GRAPH\\r\\nAND SESSION MODEL, BUT SINCE THEN I'VE GOT MY HEAD AROUND MOST OF THE QUIRKS AND\\r\\nTWISTS.\\r\\n\\r\\nTHIS SHORT ARTICLE IS NO INTRODUCTION TO TENSORFLOW, BUT INSTEAD OFFERS SOME\\r\\nQUICK TIPS, MOSTLY FOCUSED ON PERFORMANCE, THAT REVEAL COMMON PITFALLS AND MAY\\r\\nBOOST YOUR MODEL AND TRAINING PERFORMANCE TO NEW LEVELS. WE'LL START WITH\\r\\nPREPROCESSING AND YOUR INPUT PIPELINE, VISIT GRAPH CONSTRUCTION AND MOVE ON TO\\r\\nDEBUGGING AND PERFORMANCE OPTIMIZATIONS.\\r\\n\\r\\nPREPROCESSING AND INPUT PIPELINES\\r\\nKEEP PREPROCESSING CLEAN AND LEAN\\r\\nARE YOU BAFFLED AT HOW LONG IT TAKES TO TRAIN YOUR RELATIVELY SIMPLE MODEL?\\r\\nCHECK YOUR PREPROCESSING! IF YOU'RE DOING ANY HEAVY PREPROCESSING LIKE\\r\\nTRANSFORMING DATA TO NEURAL NETWORK INPUTS, THOSE CAN SIGNIFICANTLY SLOW DOWN\\r\\nYOUR INFERENCE SPEED. IN MY CASE I WAS CREATING SO-CALLED 'DISTANCE MAPS',\\r\\nGRAYSCALE IMAGES USED IN \\\"DEEP INTERACTIVE OBJECT SELECTION\\\" AS ADDITIONAL\\r\\nINPUTS, USING A CUSTOM PYTHON FUNCTION. MY TRAINING SPEED TOPPED OUT AT AROUND\\r\\n2.4 IMAGES PER SECOND EVEN WHEN I SWITCHED TO A MUCH MORE POWERFUL GTX 1080. I\\r\\nTHEN NOTICED THE BOTTLENECK AND AFTER APPLYING MY FIX I WAS ABLE TO TRAIN AT\\r\\nAROUND 50 IMAGES PER SECOND.\\r\\n\\r\\nIF YOU NOTICE SUCH A BOTTLENECK THE USUAL FIRST IMPULSE IS TO OPTIMIZE THE CODE.\\r\\nBUT A MUCH MORE EFFECTIVE WAY TO STRIP AWAY COMPUTATION TIME FROM YOUR TRAINING\\r\\nPIPELINE IS TO MOVE THE PREPROCESSING INTO A ONE-TIME OPERATION THAT GENERATES\\r\\nTFRECORD FILES. YOUR HEAVY PREPROCESSING IS ONLY DONE ONCE TO CREATE TFRECORDS\\r\\nFOR ALL YOUR TRAINING DATA AND YOUR PIPELINE BOILS DOWN TO LOADING THE RECORDS.\\r\\nEVEN IF YOU WANT TO INTRODUCE SOME KIND OF RANDOMNESS TO AUGMENT YOUR DATA, ITS\\r\\nWORTH TO THINK ABOUT CREATING THE DIFFERENT VARIATIONS ONCE INSTEAD OF BLOATING\\r\\nYOUR PIPELINE.\\r\\n\\r\\nWATCH YOUR QUEUES\\r\\nA WAY TO NOTICE EXPENSIVE PREPROCESSING PIPELINES ARE THE QUEUE GRAPHS IN\\r\\nTENSORBOARD. THESE ARE GENERATED AUTOMATICALLY IF YOU USE THE FRAMEWORKS\\r\\nQUEUERUNNERS AND STORE THE SUMMARIES IN A FILE. THE GRAPHS SHOW IF YOUR MACHINE\\r\\nWAS ABLE TO KEEP THE QUEUES FILLED. IF YOU NOTICE NEGATIVE SPIKES IN THE GRAPHS\\r\\nYOUR SYSTEM IS UNABLE TO GENERATE NEW DATA IN THE TIME YOUR MACHINE WANTS TO\\r\\nPROCESS ONE BATCH. ONE OF THE REASONS FOR THIS WAS ALREADY DISCUSSED IN THE\\r\\nPREVIOUS SECTION. THE MOST COMMON REASON IN MY EXPERIENCE IS LARGE MIN_AFTER_DEQUEUE VALUES. IF YOUR QUEUES TRY TO KEEP LOTS OF RECORDS IN MEMORY, THEY CAN EASILY\\r\\nSATURATE YOUR CAPACITIES, WHICH LEADS TO SWAPPING AND SLOWS DOWN YOUR QUEUES\\r\\nSIGNIFICANTLY. OTHER REASONS COULD BE HARDWARE ISSUES LIKE TOO SLOW DISKS OR\\r\\nJUST LARGER DATA THAN YOUR SYSTEM CAN HANDLE. WHATEVER IT IS, FIXING IT WILL\\r\\nSPEED UP YOUR TRAINING PROCESS.\\r\\n\\r\\nGRAPH CONSTRUCTION AND TRAINING\\r\\nFINALIZE YOUR GRAPH\\r\\nTENSORFLOWS SEPARATE GRAPH CONSTRUCTION AND GRAPH COMPUTATION MODEL IS QUITE\\r\\nRARE IN DAY TO DAY PROGRAMMING AND CAN CAUSE SOME CONFUSION FOR BEGINNERS. THIS\\r\\nAPPLIES TO BUGS AND ERROR MESSAGES, WHICH CAN OCCUR IN THE CODE FOR THE FIRST\\r\\nTIME WHEN THE GRAPH IS BUILT, AND THEN AGAIN WHEN IT'S ACTUALLY EVALUATED, WHICH\\r\\nIS COUNTERINTUITIVE WHEN YOU ARE USED TO CODE BEING EVALUATED JUST ONCE.\\r\\n\\r\\nANOTHER ISSUE IS GRAPH CONSTRUCTION IN COMBINATION WITH TRAINING LOOPS. THESE\\r\\nLOOPS ARE USUALLY 'STANDARD' PYTHON LOOPS AND CAN THEREFORE ALTER THE GRAPH AND\\r\\nADD NEW OPERATIONS TO IT. ALTERING A GRAPH WHILE CONTINUOUSLY EVALUATING IT WILL\\r\\nCREATE A MAJOR PERFORMANCE LOSS, BUT IS RATHER HARD TO NOTICE AT FIRST.\\r\\nTHANKFULLY THERE IS AN EASY FIX. JUST FINALIZE YOUR GRAPH BEFORE STARTING YOUR\\r\\nTRAINING LOOP BY CALLING TF.GETDEFAULTGRAPH().FINALIZE() . THIS WILL LOCK THE GRAPH AND ANY ATTEMPTS TO ADD A NEW OPERATION WILL THROW\\r\\nAN ERROR. EXACTLY WHAT WE WANT.\\r\\n\\r\\nPROFILE YOUR GRAPH\\r\\nA LESS PROMINENTLY ADVERTISED FEATURE OF TENSORFLOW IS PROFILING. THERE IS A\\r\\nMECHANISM TO RECORD RUN TIMES AND MEMORY CONSUMPTION OF YOUR GRAPHS OPERATIONS.\\r\\nTHIS CAN COME IN HANDY IF YOU ARE LOOKING FOR BOTTLENECKS OR NEED TO FIND OUT IF\\r\\nA MODEL CAN BE TRAINED ON YOUR MACHINE WITHOUT SWAPPING TO THE HARD DRIVE.\\r\\n\\r\\nTO GENERATE PROFILING DATA YOU NEED TO PERFORM A SINGLE RUN THROUGH YOUR GRAPH\\r\\nWITH TRACING ENABLED:\\r\\n\\r\\n# COLLECT TRACING INFORMATION DURING THE FIFTH STEP.\\r\\nIF GLOBAL_STEP == 5:\\r\\n    # CREATE AN OBJECT TO HOLD THE TRACING DATA\\r\\n    RUN_METADATA = TF.RUNMETADATA()\\r\\n\\r\\n    # RUN ONE STEP AND COLLECT THE TRACING DATA\\r\\n    _, LOSS = SESS.RUN([TRAIN_OP, LOSS_OP], OPTIONS=TF.RUNOPTIONS(TRACE_LEVEL=TF.RUNOPTIONS.FULL_TRACE),\\r\\n        RUN_METADATA=RUN_METADATA)\\r\\n\\r\\n    # ADD SUMMARY TO THE SUMMARY WRITER\\r\\n    SUMMARY_WRITER.ADD_RUN_METADATA(RUN_METADATA, 'STEP%D', GLOBAL_STEP)\\r\\n\\r\\n\\r\\nAFTERWARDS A TIMELINE.JSON FILE IS SAVED TO THE CURRENT FOLDER AND THE TRACING DATA BECOME AVAILABLE IN\\r\\nTENSORBOARD. YOU CAN NOW EASILY SEE, HOW LONG AN OPERATION TAKES TO COMPUTE AND\\r\\nHOW MUCH MEMORY IT CONSUMES. JUST OPEN THE GRAPH VIEW IN TENSORBOARD, SELECT\\r\\nYOUR LATEST RUN ON THE LEFT AND YOU SHOULD SEE PERFORMANCE DETAILS ON THE RIGHT.\\r\\nON THE ONE HAND, THIS ALLOWS YOU TO ADJUST YOUR MODEL IN ORDER TO USE YOUR\\r\\nMACHINE AS MUCH AS POSSIBLE, ON THE OTHER HAND, IT LETS YOU FIND BOTTLENECKS IN\\r\\nYOUR TRAINING PIPELINE. IF YOU PREFER A TIMELINE VIEW, YOU CAN LOAD THE TIMELINE.JSON FILE IN GOOGLE CHROMES TRACE EVENT PROFILING TOOL .\\r\\n\\r\\nANOTHER NICE TOOL IS TFPROF , WHICH MAKES USE OF THE SAME FUNCTIONALITY FOR MEMORY AND EXECUTION TIME\\r\\nPROFILING, BUT OFFERS MORE CONVENIENCE FEATURES. ADDITIONAL STATISTICS REQUIRE\\r\\nCODE CHANGES.\\r\\n\\r\\nWATCH YOUR MEMORY\\r\\nPROFILING, AS EXPLAINED IN THE PREVIOUS SECTION, ALLOWS YOU TO KEEP AN EYE ON\\r\\nTHE MEMORY USAGE OF PARTICULAR OPERATIONS, BUT WATCHING YOUR WHOLE MODELS MEMORY\\r\\nCONSUMPTION IS EVEN MORE IMPORTANT. ALWAYS MAKE SURE, THAT YOU DON'T EXCEED YOUR\\r\\nMACHINE'S MEMORY, AS SWAPPING WILL MOST CERTAINLY SLOW DOWN YOUR INPUT PIPELINE\\r\\nAND YOUR GPU STARTS WAITING FOR NEW DATA. A SIMPLE TOP OR, AS EXPLAINED IN ONE OF THE PREVIOUS SECTIONS, THE QUEUE GRAPHS IN\\r\\nTENSORBOARD SHOULD BE SUFFICIENT FOR DETECTING SUCH BEHAVIOR. DETAILED\\r\\nINVESTIGATION CAN THEN BE DONE USING THE AFOREMENTIONED TRACING.\\r\\n\\r\\nDEBUGGING\\r\\nPRINT IS YOUR FRIEND\\r\\nMY MAIN TOOL FOR DEBUGGING ISSUES LIKE STAGNATING LOSS OR STRANGE OUTPUTS IS TF.PRINT . DUE TO THE NATURE OF NEURAL NETWORKS, LOOKING AT THE RAW VALUES OF TENSORS\\r\\nINSIDE OF YOUR MODEL USUALLY DOESN'T MAKE MUCH SENSE. NOBODY CAN INTERPRET\\r\\nMILLIONS OF FLOATING POINT NUMBERS AND SEE WHATS WRONG. BUT ESPECIALLY PRINTING\\r\\nOUT SHAPES OR MEAN VALUES CAN GIVE GREAT INSIGHTS. IF YOU ARE TRYING TO\\r\\nIMPLEMENT SOME EXISTING MODEL, THIS ALLOWS YOU TO COMPARE YOUR MODEL'S VALUES TO\\r\\nTHE ONES IN THE PAPER OR ARTICLE AND CAN HELP YOU SOLVE TRICKY ISSUES OR EXPOSE\\r\\nTYPOS IN PAPERS.\\r\\n\\r\\nWITH TENSORFLOW 1.0 WE HAVE BEEN GIVEN THE NEW TFDEBUGGER , WHICH LOOKS VERY PROMISING. I HAVEN'T USED IT YET, BUT WILL DEFINITELY TRY IT\\r\\nOUT IN THE COMING WEEKS.\\r\\n\\r\\nSET AN OPERATION EXECUTION TIMEOUT\\r\\nYOU HAVE IMPLEMENTED YOUR MODEL, LAUNCH YOUR SESSION AND NOTHING HAPPENS? THIS\\r\\nIS USUALLY CAUSED BY EMPTY QUEUES, BUT IF YOU HAVE NO IDEA, WHICH QUEUE COULD BE\\r\\nRESPONSIBLE FOR THE MISHAP THERE IS AN EASY FIX: JUST ENABLE THE OPERATION\\r\\nEXECUTION TIMEOUT WHEN CREATING YOUR SESSION AND YOUR SCRIPT WILL CRASH WHEN AN\\r\\nOPERATION EXCEEDS YOUR LIMIT:\\r\\n\\r\\nCONFIG = TF.CONFIGPROTO()\\r\\nCONFIG.OPERATION_TIMEOUT_IN_MS=5000\\r\\nSESS = TF.SESSION(CONFIG=CONFIG)\\r\\n\\r\\n\\r\\nUSING THE STACK TRACE YOU CAN THEN FIND OUT, WHICH OP CAUSES YOUR HEADACHE, FIX\\r\\nTHE ERROR AND TRAIN ON.\\r\\n\\r\\n\\r\\n--------------------------------------------------------------------------------\\r\\n\\r\\nI HOPE I COULD HELP SOME OF MY FELLOW TENSORFLOW CODERS. IF YOU FOUND AN ERROR,\\r\\nHAVE MORE TIPS OR JUST WANT TO GET IN TOUCH, PLEASE SEND ME AN EMAIL!\\r\\n\\r\\n\\r\\nSIGN UP TO RECEIVE MORE CONTENT LIKE THIS PLUS INDUSTRY NEWS, CODE AND TUTORIALS EVERY WEEK FRESH TO YOUR INBOX.\\r\\nNo spam. One-click unsubscribe.\",\n          \"Homepage Stats and Bots Follow Sign in Get started * Home\\r\\n * DATA SCIENCE\\r\\n * ANALYTICS\\r\\n * STARTUPS\\r\\n * BOTS\\r\\n * DESIGN\\r\\n * Subscribe\\r\\n * \\r\\n * \\ud83e\\udd16 TRY STATSBOT FREE\\r\\n * \\r\\n\\r\\nEduard Tyantov Blocked Unblock Follow Following Mail.ru Group, Head of Machine Learning Team Dec 21, 2017\\r\\n--------------------------------------------------------------------------------\\r\\n\\r\\nDEEP LEARNING ACHIEVEMENTS OVER THE PAST YEAR\\r\\nGREAT DEVELOPMENTS IN TEXT, VOICE, AND COMPUTER VISION TECHNOLOGIES\\r\\nAt Statsbot , we\\u2019re constantly reviewing the deep learning achievements to improve our\\r\\nmodels and product. Around Christmas time, our team decided to take stock of the\\r\\nrecent achievements in deep learning over the past year (and a bit longer). We\\r\\ntranslated the article by a data scientist, Ed Tyantov, to tell you about the\\r\\nmost significant developments that can affect our future.\\r\\n\\r\\n1. TEXT\\r\\n1.1. GOOGLE NEURAL MACHINE TRANSLATION\\r\\nAlmost a year ago, Google announced the launch of a new model for Google Translate . The company described in detail the network architecture \\u2014 Recurrent Neural Network (RNN).\\r\\n\\r\\nMachine Learning Translation and the Google Translate Algorithm The basic\\r\\nprinciples of machine translation engines blog.statsbot.coThe key outcome: closing down the gap with humans in accuracy of the translation\\r\\nby 55\\u201385% (estimated by people on a 6-point scale). It is difficult to reproduce\\r\\ngood results with this model without the huge dataset that Google has.\\r\\n\\r\\n1.2. NEGOTIATIONS. WILL THERE BE A DEAL?\\r\\nYou probably heard the silly news that Facebook turned off its chatbot , which went out of control and made up its own language. This chatbot was\\r\\ncreated by the company for negotiations. Its purpose is to conduct text\\r\\nnegotiations with another agent and reach a deal: how to divide items (books,\\r\\nhats, etc.) by two. Each agent has his own goal in the negotiations that the\\r\\nother does not know about. It\\u2019s impossible to leave the negotiations without a\\r\\ndeal.\\r\\n\\r\\nFor training, they collected a dataset of human negotiations and trained a\\r\\nsupervised recurrent network. Then, they took a reinforcement learning trained\\r\\nagent and trained it to talk with itself, setting a limit \\u2014 the similarity of\\r\\nthe language to human.\\r\\n\\r\\nThe bot has learned one of the real negotiation strategies \\u2014 showing a fake\\r\\ninterest in certain aspects of the deal, only to give up on them later and\\r\\nbenefit from its real goals. It has been the first attempt to create such an\\r\\ninteractive bot, and it was quite successful.\\r\\n\\r\\nFull story is in this article , and the code is publicly available .\\r\\n\\r\\nCertainly, the news that the bot has allegedly invented a language was inflated\\r\\nfrom scratch. When training (in negotiations with the same agent), they disabled\\r\\nthe restriction of the similarity of the text to human, and the algorithm\\r\\nmodified the language of interaction. Nothing unusual.\\r\\n\\r\\nCreepiest Stories in Artificial Intelligence Development Scary things about AI:\\r\\nfrom virtual cannibalism to racist monsters blog.statsbot.coOver the past year, recurrent networks have been actively developed and used in\\r\\nmany tasks and applications. The architecture of RNNs has become much more\\r\\ncomplicated, but in some areas similar results were achieved by simple\\r\\nfeedforward-networks \\u2014 DSSM . For example, Google has reached the same quality , as with LSTM previously, for its mail feature Smart Reply. In addition,\\r\\nYandex launched a new search engine based on such networks.\\r\\n\\r\\n2. VOICE\\r\\n2.1. WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\\r\\nEmployees of DeepMind reported in their article about generating audio. Briefly, researchers made an autoregressive\\r\\nfull-convolution WaveNet model based on previous approaches to image generation\\r\\n( PixelRNN and PixelCNN ).\\r\\n\\r\\nThe network was trained end-to-end: text for the input, audio for the output.\\r\\nThe researches got an excellent result as the difference compared to human has\\r\\nbeen reduced by 50%.\\r\\n\\r\\nThe main disadvantage of the network is a low productivity as, because of the\\r\\nautoregression, sounds are generated sequentially and it takes about 1\\u20132 minutes\\r\\nto create one second of audio.\\r\\n\\r\\nLook at\\u2026 sorry, hear this example.\\r\\n\\r\\nIf you remove the dependence of the network on the input text and leave only the\\r\\ndependence on the previously generated phoneme, then the network will generate\\r\\nphonemes similar to the human language, but they will be meaningless.\\r\\n\\r\\nHear the example of the generated voice.\\r\\n\\r\\nThis same model can be applied not only to speech, but also, for example, to\\r\\ncreating music. Imagine audio generated by the model , which was taught using the dataset of a piano game (again without any\\r\\ndependence on the input data).\\r\\n\\r\\nRead a full version of DeepMind research if you\\u2019re interested.\\r\\n\\r\\n2.2. LIP READING\\r\\nLip reading is another deep learning achievement and victory over humans.\\r\\n\\r\\nGoogle Deepmind, in collaboration with Oxford University, reported in the\\r\\narticle, \\u201cLip Reading Sentences in the Wild\\u201d on how their model, which had been trained on a television dataset, was able to\\r\\nsurpass the professional lip reader from the BBC channel.\\r\\n\\r\\nThere are 100,000 sentences with audio and video in the dataset. Model: LSTM on\\r\\naudio, and CNN + LSTM on video. These two state vectors are fed to the final\\r\\nLSTM, which generates the result (characters).\\r\\n\\r\\nDifferent types of input data were used during training: audio, video, and audio\\r\\n+ video. In other words, it is an \\u201comnichannel\\u201d model.\\r\\n\\r\\n2.3. SYNTHESIZING OBAMA: SYNCHRONIZATION OF THE LIP MOVEMENT FROM AUDIO\\r\\nThe University of Washington has done a serious job of generating the lip movements of former US President Obama. The choice fell\\r\\non him due to the huge number of his performance recordings online (17 hours of\\r\\nHD video).\\r\\n\\r\\nThey couldn\\u2019t get along with just the network as they got too many artifacts.\\r\\nTherefore, the authors of the article made several crutches (or tricks, if you\\r\\nlike) to improve the texture and timings.\\r\\n\\r\\nYou can see that the results are amazing . Soon, you couldn\\u2019t trust even the video with the president.\\r\\n\\r\\n3. COMPUTER VISION\\r\\n3.1. OCR: GOOGLE MAPS AND STREET VIEW\\r\\nIn their post and article , Google Brain Team reported on how they introduced a new OCR (Optical\\r\\nCharacter Recognition) engine into its Maps, through which street signs and\\r\\nstore signs are recognized.\\r\\n\\r\\nIn the process of technology development, the company compiled a new FSNS (French Street Name Signs), which contains many complex cases.\\r\\n\\r\\nTo recognize each sign, the network uses up to four of its photos. The features\\r\\nare extracted with the CNN, scaled with the help of the spatial attention (pixel\\r\\ncoordinates are taken into account), and the result is fed to the LSTM.\\r\\n\\r\\nThe same approach is applied to the task of recognizing store names on\\r\\nsignboards (there can be a lot of \\u201cnoise\\u201d data, and the network itself must\\r\\n\\u201cfocus\\u201d in the right places). This algorithm was applied to 80 billion photos.\\r\\n\\r\\n3.2. VISUAL REASONING\\r\\nThere is a type of task called visual reasoning, where a neural network is asked\\r\\nto answer a question using a photo. For example: \\u201cIs there a same size rubber\\r\\nthing in the picture as a yellow metal cylinder?\\u201d The question is truly\\r\\nnontrivial, and until recently, the problem was solved with an accuracy of only\\r\\n68.5%.\\r\\n\\r\\nAnd again the breakthrough was achieved by the team from Deepmind: on the CLEVR dataset they reached a super-human accuracy of 95.5% .\\r\\n\\r\\nThe network architecture is very interesting:\\r\\n\\r\\n 1. Using the pre-trained LSTM on the text question, we get the embedding of the\\r\\n    question.\\r\\n 2. Using the CNN (just four layers) with the picture, we get feature maps\\r\\n    (features that characterize the picture).\\r\\n 3. Next, we form pairwise combinations of coordinatewise slices on the feature\\r\\n    maps (yellow, blue, red in the picture below), adding coordinates and text\\r\\n    embedding to each of them.\\r\\n 4. We drive all these triples through another network and sum up.\\r\\n 5. The resulting presentation is run through another feedforward network, which\\r\\n    provides the answer on the softmax.\\r\\n\\r\\n3.3. PIX2CODE\\r\\nAn interesting application of neural networks was created by the company Uizard : generating a layout code according to a screenshot from the interface\\r\\ndesigner.\\r\\n\\r\\nThis is an extremely useful application of neural networks, which can make life\\r\\neasier when developing software. The authors claim that they reached 77%\\r\\naccuracy. However, this is still under research and there is no talk on real\\r\\nusage yet.\\r\\n\\r\\nThere is no code or dataset in open source, but they promise to upload it.\\r\\n\\r\\n3.4. SKETCHRNN: TEACHING A MACHINE TO DRAW\\r\\nPerhaps you\\u2019ve seen Quick, Draw! from Google, where the goal is to draw sketches of various objects in 20\\r\\nseconds. The corporation collected this dataset in order to teach the neural\\r\\nnetwork to draw, as Google described in their blog and article .\\r\\n\\r\\nThe collected dataset consists of 70 thousand sketches, which eventually became publicly available . Sketches are not pictures, but detailed vector representations of drawings\\r\\n(at which point the user pressed the \\u201cpencil,\\u201d released where the line was\\r\\ndrawn, and so on).\\r\\n\\r\\nResearchers have trained the Sequence-to-Sequence Variational Autoencoder (VAE)\\r\\nusing RNN as a coding/decoding mechanism.\\r\\n\\r\\nEventually, as befits the auto-encoder, the model received a latent vector that\\r\\ncharacterizes the original picture.\\r\\n\\r\\nWhereas the decoder can extract a drawing from this vector, you can change it\\r\\nand get new sketches.\\r\\n\\r\\nAnd even perform vector arithmetic to create a catpig:\\r\\n\\r\\n3.5. GANS\\r\\nOne of the hottest topics in Deep Learning is Generative Adversarial Networks\\r\\n(GANs). Most often, this idea is used to work with images, so I will explain the\\r\\nconcept using them.\\r\\n\\r\\nGenerative Adversarial Networks (GANs): Engine and Applications How generative\\r\\nadversarial nets are used to make our life better blog.statsbot.coThe idea is in the competition of two networks \\u2014 the generator and the\\r\\ndiscriminator. The first network creates a picture, and the second one tries to\\r\\nunderstand whether the picture is real or generated.\\r\\n\\r\\nSchematically it looks like this:\\r\\n\\r\\nDuring training, the generator from a random vector (noise) generates an image\\r\\nand feeds it to the input of the discriminator, which says whether it is fake or\\r\\nnot. The discriminator is also given real images from the dataset.\\r\\n\\r\\nIt is difficult to train such construction, as it is hard to find the\\r\\nequilibrium point of two networks. Most often the discriminator wins and the\\r\\ntraining stagnates. However, the advantage of the system is that we can solve\\r\\nproblems in which it is difficult for us to set the loss-function (for example,\\r\\nimproving the quality of the photo) \\u2014 we give it to the discriminator.\\r\\n\\r\\nA classic example of the GAN training result is pictures of bedrooms or people\\r\\n\\r\\nPreviously, we considered the auto-coding (Sketch-RNN), which encodes the\\r\\noriginal data into a latent representation. The same thing happens with the\\r\\ngenerator.\\r\\n\\r\\nThe idea of generating an image using a vector is clearly shown in this project in the example of faces. You can change the vector and see how the faces\\r\\nchange.\\r\\n\\r\\nThe same arithmetic works over the latent space: \\u201ca man in glasses\\u201d minus \\u201ca\\r\\nman\\u201d plus a \\u201cwoman\\u201d is equal to \\u201ca woman with glasses.\\u201d\\r\\n\\r\\n3.6. CHANGING FACE AGE WITH GANS\\r\\nIf you teach a controlled parameter to the latent vector during training, when\\r\\nyou generate it, you can change it and so manage the necessary image in the\\r\\npicture. This approach is called conditional GAN.\\r\\n\\r\\nSo did the authors of the article, \\u201cFace Aging With Conditional Generative Adversarial Networks.\\u201d Having trained the engine on the IMDB dataset with a known age of actors, the\\r\\nresearchers were given the opportunity to change the face age of the person.\\r\\n\\r\\n3.7. PROFESSIONAL PHOTOS\\r\\nGoogle has found another interesting application to GAN \\u2014 the choice and improvement of photos. GAN was trained on a professional photo\\r\\ndataset: the generator is trying to improve bad photos (professionally shot and\\r\\ndegraded with the help of special filters), and the discriminator \\u2014 to\\r\\ndistinguish \\u201cimproved\\u201d photos and real professional ones.\\r\\n\\r\\nA trained algorithm went through Google Street View panoramas in search of the\\r\\nbest composition and received some pictures of professional and\\r\\nsemi-professional quality (as per photographers\\u2019 rating).\\r\\n\\r\\n3.8. SYNTHESIZATION OF AN IMAGE FROM A TEXT DESCRIPTION\\r\\nAn impressive example of GANs is generating images using text.\\r\\n\\r\\nThe authors of this research suggest embedding text into the input of not only a generator (conditional\\r\\nGAN), but also a discriminator, so that it verifies the correspondence of the\\r\\ntext to the picture. In order to make sure the discriminator learned to perform\\r\\nhis function, in addition to training they added pairs with an incorrect text\\r\\nfor the real pictures.\\r\\n\\r\\n3.9. PIX2PIX\\r\\nOne of the eye-catching articles of 2016 is, \\u201cImage-to-Image Translation with Conditional Adversarial Networks\\u201d by Berkeley AI Research (BAIR). Researchers solved the problem of\\r\\nimage-to-image generation, when, for example, it was required to create a map\\r\\nusing a satellite image, or realistic texture of the objects using their sketch.\\r\\n\\r\\nHere is another example of the successful performance of conditional GANs. In\\r\\nthis case, the condition goes to the whole picture. Popular in image\\r\\nsegmentation, UNet was used as the architecture of the generator, and a new\\r\\nPatchGAN classifier was used as a discriminator for combating blurred images\\r\\n(the picture is cut into N patches, and the prediction of fake/real goes for\\r\\neach of them separately).\\r\\n\\r\\nChristopher Hesse made the nightmare cat demo, which attracted great interest from the users.\\r\\n\\r\\nYou can find a source code here.\\r\\n\\r\\n3.10. CYCLEGAN\\r\\nIn order to apply Pix2Pix, you need a dataset with the corresponding pairs of\\r\\npictures from different domains. In the case, for example, with cards, it is not\\r\\na problem to assemble such a dataset. However, if you want to do something more\\r\\ncomplicated like \\u201ctransfiguring\\u201d objects or styling, then pairs of objects\\r\\ncannot be found in principle.\\r\\n\\r\\nTherefore, authors of Pix2Pix decided to develop their idea and came up with\\r\\nCycleGAN for transfer between different domains of images without specific pairs\\r\\n\\u2014 \\u201cUnpaired Image-to-Image Translation.\\u201d\\r\\n\\r\\nThe idea is to teach two pairs of generator-discriminators to transfer the image\\r\\nfrom one domain to another and back, while we require a cycle consistency \\u2014\\r\\nafter a sequential application of the generators, we should get an image similar\\r\\nto the original L1 loss. A cyclic loss is required to ensure that the generator\\r\\ndid not just begin to transfer pictures of one domain to pictures from another\\r\\ndomain, which are completely unrelated to the original image.\\r\\n\\r\\nThis approach allows you to learn the mapping of horses -> zebras.\\r\\n\\r\\nSuch transformations are unstable and often create unsuccessful options:\\r\\n\\r\\nYou can find a source code here.\\r\\n\\r\\n3.11. DEVELOPMENT OF MOLECULES IN ONCOLOGY\\r\\nMachine learning is now coming to medicine. In addition to recognizing\\r\\nultrasound, MRI, and diagnosis, it can be used to find new drugs to fight\\r\\ncancer.\\r\\n\\r\\nWe already reported in detail about this research . Briefly, with the help of Adversarial Autoencoder (AAE), you can learn the\\r\\nlatent representation of molecules and then use it to search for new ones. As a\\r\\nresult, 69 molecules were found, half of which are used to fight cancer, and the\\r\\nothers have serious potential.\\r\\n\\r\\n3.12. ADVERSARIAL-ATTACKS\\r\\nTopics with adversarial-attacks are actively explored. What are\\r\\nadversarial-attacks? Standard networks trained, for example, on ImageNet, are\\r\\ncompletely unstable when adding special noise to the classified picture. In the\\r\\nexample below, we see that the picture with noise for the human eye is\\r\\npractically unchanged, but the model goes crazy and predicts a completely\\r\\ndifferent class.\\r\\n\\r\\nStability is achieved with, for example, the Fast Gradient Sign Method (FGSM):\\r\\nhaving access to the parameters of the model, you can make one or several gradient steps towards the desired class and change the original picture.\\r\\n\\r\\nOne of the tasks on Kaggle is related to this: the participants are encouraged to create universal\\r\\nattacks/defenses, which are all eventually run against each other to determine\\r\\nthe best.\\r\\n\\r\\nWhy should we even investigate these attacks? First, if we want to protect our\\r\\nproducts, we can add noise to the captcha to prevent spammers from recognizing\\r\\nit automatically. Secondly, algorithms are more and more involved in our lives \\u2014\\r\\nface recognition systems and self-driving cars. In this case, attackers can use\\r\\nthe shortcomings of the algorithms.\\r\\n\\r\\nHere is an example of when special glasses allow you to deceive the face\\r\\nrecognition system and \\u201cpass yourself off as another person.\\u201d So, we need to\\r\\ntake possible attacks into account when teaching models.\\r\\n\\r\\nSuch manipulations with signs also do not allow them to be recognized correctly.\\r\\n\\r\\n\\u2022 A set of articles from the organizers of the contest.\\r\\n\\u2022 Already written libraries for attacks: cleverhans and foolbox.\\r\\n\\r\\n4. REINFORCEMENT LEARNING\\r\\nReinforcement learning (RL), or learning with reinforcement is also one of the\\r\\nmost interesting and actively developing approaches in machine learning.\\r\\n\\r\\nThe essence of the approach is to learn the successful behavior of the agent in\\r\\nan environment that gives a reward through experience \\u2014 just as people learn\\r\\nthroughout their lives.\\r\\n\\r\\nRL is actively used in games, robots, and system management (traffic, for\\r\\nexample).\\r\\n\\r\\nOf course, everyone has heard about AlphaGo\\u2019s victories in the game over the best professionals . Researchers were using RL for training: the bot played with itself to improve\\r\\nits strategies.\\r\\n\\r\\n4.1. REINFORCEMENT TRAINING WITH UNCONTROLLED AUXILIARY TASKS\\r\\nIn previous years, DeepMind had learned using DQN to play arcade games better than humans. Currently, algorithms are being taught\\r\\nto play more complex games like Doom .\\r\\n\\r\\nMuch of the attention is paid to learning acceleration because experience of the\\r\\nagent in interaction with the environment requires many hours of training on\\r\\nmodern GPUs.\\r\\n\\r\\nIn his blog, Deepmind reported that the introduction of additional losses (auxiliary tasks), such as the\\r\\nprediction of a frame change (pixel control) so that the agent better\\r\\nunderstands the consequences of the actions, significantly speeds up learning.\\r\\n\\r\\nLearning results:\\r\\n\\r\\n4.2. Learning robots\\r\\nIn OpenAI, they have been actively studying an agent\\u2019s training by humans in a\\r\\nvirtual environment, which is safer for experiments than in real life.\\r\\n\\r\\nIn one of the studies , the team showed that one-shot learning is possible: a person shows in VR how\\r\\nto perform a certain task, and one demonstration is enough for the algorithm to\\r\\nlearn it and then reproduce it in real conditions.\\r\\n\\r\\nIf only it was so easy with people. :)\\r\\n\\r\\n4.3. LEARNING ON HUMAN PREFERENCES\\r\\nHere is the work of OpenAI and DeepMind on the same topic . The bottom line is that an agent has a task, the algorithm provides two\\r\\npossible solutions for the human and indicates which one is better. The process\\r\\nis repeated iteratively and the algorithm for 900 bits of feedback (binary\\r\\nmarkup) from the person learned how to solve the problem.\\r\\n\\r\\nAs always, the human must be careful and think of what he is teaching the\\r\\nmachine. For example, the evaluator decided that the algorithm really wanted to\\r\\ntake the object, but in fact, he just simulated this action.\\r\\n\\r\\n4.4. MOVEMENT IN COMPLEX ENVIRONMENTS\\r\\nThere is another study from DeepMind . To teach the robot complex behavior (walk, jump, etc.), and even do it\\r\\nsimilar to the human, you have to be heavily involved with the choice of the\\r\\nloss function, which will encourage the desired behavior. However, it would be\\r\\npreferable that the algorithm learned complex behavior itself by leaning with\\r\\nsimple rewards.\\r\\n\\r\\nResearchers managed to achieve this: they taught agents (body emulators) to\\r\\nperform complex actions by constructing a complex environment with obstacles and\\r\\nwith a simple reward for progress in movement.\\r\\n\\r\\nYou can watch the impressive video with results . However, it\\u2019s much more fun to watch it with a superimposed sound!\\r\\n\\r\\nFinally, I will give a link to the recently published algorithms for learning RL from OpenAI . Now you can use more advanced solutions than the standard DQN.\\r\\n\\r\\n5. OTHER\\r\\n5.1. COOLING THE DATA CENTER\\r\\nIn July 2017, Google reported that it took advantage of DeepMind\\u2019s development in machine learning to reduce the energy costs of its data center.\\r\\n\\r\\nBased on the information from thousands of sensors in the data center, Google\\r\\ndevelopers trained a neural network ensemble to predict PUE (Power Usage\\r\\nEffectiveness) and more efficient data center management. This is an impressive\\r\\nand significant example of the practical application of ML.\\r\\n\\r\\n5.2. ONE MODEL FOR ALL TASKS\\r\\nAs you know, trained models are poorly transferred from task to task, as each\\r\\ntask has to be trained for a specific model. A small step towards the\\r\\nuniversality of the models was done by Google Brain in his article \\u201cOne Model To Learn The All.\\u201d\\r\\n\\r\\nResearchers have trained a model that performs eight tasks from different\\r\\ndomains (text, speech, and images). For example, translation from different\\r\\nlanguages, text parsing, and image and sound recognition.\\r\\n\\r\\nIn order to achieve this, they built a complex network architecture with various\\r\\nblocks to process different input data and generate a result. The blocks for the\\r\\nencoder/decoder fall into three types: convolution, attention, and gated mixture of experts (MoE).\\r\\n\\r\\nMain results of learning:\\r\\n\\r\\n * Almost perfect models were obtained (the authors did not fine tune the\\r\\n   hyperparameters).\\r\\n * There is a transfer of knowledge between different domains, that is, on tasks\\r\\n   with a lot of data, the performance will be almost the same. And it is better\\r\\n   on small problems (for example, on parsing).\\r\\n * Blocks needed for different tasks do not interfere with each other and even\\r\\n   sometimes help, for example, MoE \\u2014 for the Imagenet task.\\r\\n\\r\\nBy the way, this model is present in tensor2tensor .\\r\\n\\r\\n5.3. LEARNING ON IMAGENET IN ONE HOUR\\r\\nIn their post, Facebook staff told us how their engineers were able to teach the\\r\\nResnet-50 model on Imagenet in just one hour. Truth be told, this required a\\r\\ncluster of 256 GPUs (Tesla P100).\\r\\n\\r\\nThey used Gloo and Caffe2 for distributed learning . To make the process effective, it was necessary to adapt the learning\\r\\nstrategy with a huge batch (8192 elements): gradient averaging, warm-up phase,\\r\\nspecial learning rate, etc.\\r\\n\\r\\nAs a result, it was possible to achieve an efficiency of 90% when scaling from 8\\r\\nto 256 GPU. Now researchers from Facebook can experiment even faster, unlike\\r\\nmere mortals without such a cluster.\\r\\n\\r\\n6. NEWS\\r\\n6.1. SELF-DRIVING CARS\\r\\nThe self-driving car sphere is intensively developing, and the cars are actively\\r\\ntested. From the relatively recent events, we can note the purchase of Intel\\r\\nMobilEye, the scandals around Uber and Google technologies stolen by their former\\r\\nemployee , the first death when using an autopilot , and much more.\\r\\n\\r\\nI will note one thing: Google Waymo is launching a beta program . Google is a pioneer in this field, and it is assumed that their technology is\\r\\nvery good because cars have been driven more than 3 million miles.\\r\\n\\r\\nAs to more recent events, self-driving cars have been allowed to travel across\\r\\nall US states.\\r\\n\\r\\n6.2. HEALTHCARE\\r\\nAs I said, modern ML is beginning to be introduced into medicine. For example, Google collaborates with a medical center to help with diagnosis.\\r\\n\\r\\nDeepmind has even established a separate unit.\\r\\n\\r\\nThis year, under the program of the Data Science Bowl, there was a competition held to predict lung cancer in a year on the basis of detailed images with a prize fund of one million dollars.\\r\\n\\r\\n6.3. INVESTMENTS\\r\\nCurrently, there are heavy investments in ML as it was before with BigData.\\r\\n\\r\\nChina invested $150 billion in AI to become the world leader in the industry.\\r\\n\\r\\nFor comparison, Baidu Research employs 1,300 people, and in the same FAIR\\r\\n(Facebook) \\u2014 80. At the last KDD, Alibaba employees talked about their parameter\\r\\nserver KungPeng , which runs on 100 billion samples with a trillion parameters, which \\u201cbecomes\\r\\na common task\\u201d \\u00a9.\\r\\n\\r\\nYou can draw your own conclusions, it\\u2019s never too late to study machine learning . In one way or another, over time, all developers will use machine learning,\\r\\nwhich will become one of the common skills, as it is today \\u2014 the ability to work\\r\\nwith databases.\\r\\n\\r\\nLink to the original post .\\r\\n\\r\\nYOU\\u2019D ALSO LIKE:\\r\\nSQL Window Functions Tutorial for Business Analysis The most popular business\\r\\nproblems solved with SQL blog.statsbot.co A Guide for Customer Retention Analysis with SQL How to make customer retention\\r\\ncurves and cohort analysis the right way blog.statsbot.co SQL Queries for Funnel Analysis A template for building SQL funnel queries\\r\\nblog.statsbot.co * Machine Learning\\r\\n * Deep Learning\\r\\n * Data Science\\r\\n * AI\\r\\n * Computer Vision\\r\\n\\r\\nOne clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.\\r\\n\\r\\n3.9K 9 Blocked Unblock Follow FollowingEDUARD TYANTOV\\r\\nMail.ru Group, Head of Machine Learning Team\\r\\n\\r\\nFollowSTATS AND BOTS\\r\\nData stories on machine learning and analytics. From Statsbot\\u2019s makers.\\r\\n\\r\\n * 3.9K\\r\\n * \\r\\n * \\r\\n * \\r\\n\\r\\nNever miss a story from Stats and Bots , when you sign up for Medium. Learn more Never miss a story from Stats and Bots Get updates Get updates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1022,\n        \"samples\": [\n          \"we take a look at long-time Compose customer, Emarsys, who runs Compose-hosted MongoDB, PostgreSQL and Redis for their micro-services architected marketing automation platform.\",\n          \"Python for loops are for iterating through sequences like lists, strings, dictionaries or ranges. In this article, I\\u2019ll show you everything you need to know about them: the syntax, the logic and best practices too!\",\n          \"Cloudant will soon run on the Apache CouchDB 2.0 code base. Today, we're announcing a sandbox cluster for functional testing. Here's what's new.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_full_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1051,\n        \"samples\": [\n          \"How IBM builds an effective data science team\",\n          \"Improved Performance for Redis Cache Mode on Compose\",\n          \"A Moving Average Trading Strategy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Live\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 303,\n        \"min\": 0,\n        \"max\": 1050,\n        \"num_unique_values\": 1051,\n        \"samples\": [\n          352\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_content"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-eeb9abcb-be36-474b-83a5-fe11b8d2f2db\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeb9abcb-be36-474b-83a5-fe11b8d2f2db')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-eeb9abcb-be36-474b-83a5-fe11b8d2f2db button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-eeb9abcb-be36-474b-83a5-fe11b8d2f2db');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-0516591f-f5e2-417a-911d-b0f6140ff1c0\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0516591f-f5e2-417a-911d-b0f6140ff1c0')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-0516591f-f5e2-417a-911d-b0f6140ff1c0 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "\n",
    "# matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()\n",
    "\n",
    "# Show df_content to get an idea of the data\n",
    "df_content.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcPQBgetvlK1"
   },
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  \n",
    "\n",
    "**Data Overview:**\n",
    "- **User-Item Interactions**: 45,993 total interactions across 5,148 unique users and 714 unique articles\n",
    "- **Articles Dataset**: 1,056 total articles with content metadata\n",
    "- **Data Sparsity**: 99.08% sparse user-item matrix, indicating limited user engagement\n",
    "- **User Behavior**: Median of 3 interactions per user, with maximum of 364 interactions by a single user\n",
    "- **Article Popularity**: Most popular article (ID: 1429.0) has 937 interactions, showing significant variation in article engagement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qQ70DuFvvlK2"
   },
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = df.groupby('email').size().median()  # 50% of individuals interact with this number of articles or fewer\n",
    "max_views_by_user = df.groupby('email').size().max()  # The maximum number of user-article interactions by any 1 user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7boeH4V-vlK2"
   },
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvWsZq9svlK3",
    "outputId": "1f2c67ee-48ab-4464-a535-3a1edcea4d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate articles: 10\n"
     ]
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "duplicate_articles = df_content[df_content.duplicated(subset=['article_id'], keep=False)]\n",
    "print(f\"Number of duplicate articles: {len(duplicate_articles)}\")\n",
    "\n",
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content = df_content.drop_duplicates(subset=['article_id'], keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PicH1jQVvlK3"
   },
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values)<br>\n",
    "**d.** The number of user-article interactions in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LTJU58WZvlK4"
   },
   "outputs": [],
   "source": [
    "unique_articles = df['article_id'].nunique()  # The number of unique articles that have at least one interaction\n",
    "total_articles = df_content['article_id'].nunique()  # The number of unique articles on the IBM platform\n",
    "unique_users = df['email'].nunique()  # The number of unique users\n",
    "user_article_interactions = len(df)  # The number of user-article interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhn9wFx0vlK4"
   },
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was find using other information that all of these null values likely belonged to a single user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7I5PedPvlK5",
    "outputId": "32407fe6-bd78-4838-8f68-105886722135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "most_viewed_article_id = str(df.groupby('article_id').size().idxmax())  # The most viewed article in the dataset as a string with one value following the decimal\n",
    "max_views = df.groupby('article_id').size().max()  # The most viewed article in the dataset was viewed how many times?\n",
    "\n",
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "\n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "\n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()\n",
    "\n",
    "## If you stored all your results in the variable names above,\n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awfM77LYvlK6"
   },
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "**Rank-Based Recommendation Strategy:**\n",
    "- **Approach**: Recommend articles based on overall popularity (interaction count)\n",
    "- **Advantages**: Simple, effective for new users, no cold start problem\n",
    "- **Use Case**: Baseline recommendations and new user onboarding\n",
    "- **Top Articles**: The most popular articles include machine learning, data science, and analytics topics\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6T--HunvlK7",
    "outputId": "d4018765-8005-4939-f8c6-4f64dbb6fd4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
      "['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n",
      "Oops! The top_5 list doesn't look how we expected.  Try again.\n",
      "Oops! The top_10 list doesn't look how we expected.  Try again.\n",
      "Oops! The top_20 list doesn't look how we expected.  Try again.\n"
     ]
    }
   ],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "\n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles\n",
    "\n",
    "    '''\n",
    "    # Count interactions per article and get top n\n",
    "    top_article_ids = df.groupby('article_id').size().sort_values(ascending=False).head(n).index\n",
    "\n",
    "    # Get the titles for these articles\n",
    "    top_articles = []\n",
    "    for article_id in top_article_ids:\n",
    "        title = df[df['article_id'] == article_id]['title'].iloc[0]\n",
    "        top_articles.append(title)\n",
    "\n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "\n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article ids\n",
    "\n",
    "    '''\n",
    "    # Count interactions per article and get top n\n",
    "    top_articles = df.groupby('article_id').size().sort_values(ascending=False).head(n).index.tolist()\n",
    "\n",
    "    # Convert to strings to match expected format\n",
    "    top_articles = [str(aid) for aid in top_articles]\n",
    "\n",
    "    return top_articles # Return the top article ids\n",
    "\n",
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10, df))\n",
    "\n",
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nWXLN92vlK8"
   },
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "**Collaborative Filtering Approach:**\n",
    "- **Method**: Find users with similar interaction patterns and recommend articles they liked\n",
    "- **Similarity Metric**: Dot product between user interaction vectors (binary similarity)\n",
    "- **Advantages**: Personalized recommendations based on user behavior patterns\n",
    "- **Challenges**: Cold start problem for new users, scalability with large user base\n",
    "- **Matrix Dimensions**: 5,149 users × 714 articles (99.08% sparse)\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**.\n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vEGxL81vlK8",
    "outputId": "7b413aa4-c29a-4bb4-a141-a2d9f1b86935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "\n",
    "    OUTPUT:\n",
    "    user_item - user item matrix\n",
    "\n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with\n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Create user-item matrix\n",
    "    user_item = df.groupby(['user_id', 'article_id']).size().unstack(fill_value=0)\n",
    "    user_item = (user_item > 0).astype(int)\n",
    "\n",
    "    return user_item # return the user_item matrix\n",
    "\n",
    "user_item = create_user_item_matrix(df)\n",
    "\n",
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8fPRcVCvlK8"
   },
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users.\n",
    "\n",
    "Use the tests to test your function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YSXou4-vlK8",
    "outputId": "123c8a04-d85b-4425-faf6-5c6de368a8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 3782, 23, 203, 4459, 131, 3870, 4201, 46, 395]\n",
      "The 5 most similar users to user 3933 are: [1, 3782, 23, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles:\n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "\n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "\n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "\n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    user_vector = user_item.loc[user_id]\n",
    "    similarities = user_item.dot(user_vector)\n",
    "\n",
    "    # sort by similarity\n",
    "    similarities = similarities.sort_values(ascending=False)\n",
    "\n",
    "    # create list of just the ids\n",
    "    similar_users = similarities.index.tolist()\n",
    "\n",
    "    # remove the own user's id\n",
    "    similar_users.remove(user_id)\n",
    "\n",
    "    return similar_users # return a list of the users in order from most to least similar\n",
    "\n",
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdxOBqLMvlK9"
   },
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzM985k0vlK9",
    "outputId": "d9ccc6a3-b47f-4f90-ae4a-61038abf0de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "\n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids\n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Get article names for the given article IDs\n",
    "    article_names = []\n",
    "    for article_id in article_ids:\n",
    "        # Convert string to float for comparison\n",
    "        article_id_float = float(article_id)\n",
    "        matching_articles = df[df['article_id'] == article_id_float]\n",
    "        if len(matching_articles) > 0:\n",
    "            title = matching_articles['title'].iloc[0]\n",
    "            article_names.append(title)\n",
    "        else:\n",
    "            # Handle case where article_id doesn't exist\n",
    "            article_names.append(f\"Article {article_id} not found\")\n",
    "\n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles:\n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "\n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids\n",
    "\n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # Get articles the user has interacted with\n",
    "    user_vector = user_item.loc[user_id]\n",
    "    article_ids = user_vector[user_vector == 1].index.tolist()\n",
    "\n",
    "    # Convert to strings to match expected format\n",
    "    article_ids = [str(aid) for aid in article_ids]\n",
    "\n",
    "    # Get article names\n",
    "    article_names = get_article_names(article_ids)\n",
    "\n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "\n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "\n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "\n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "\n",
    "    For the user where the number of recommended articles starts below m\n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "\n",
    "    '''\n",
    "    # Get articles the user has already seen\n",
    "    seen_articles, _ = get_user_articles(user_id)\n",
    "\n",
    "    # Get similar users\n",
    "    similar_users = find_similar_users(user_id)\n",
    "\n",
    "    # Find recommendations\n",
    "    recs = []\n",
    "    for similar_user in similar_users:\n",
    "        similar_user_articles, _ = get_user_articles(similar_user)\n",
    "\n",
    "        # Find articles similar user has seen but current user hasn't\n",
    "        new_articles = [article for article in similar_user_articles if article not in seen_articles]\n",
    "\n",
    "        # Add new articles to recommendations\n",
    "        for article in new_articles:\n",
    "            if article not in recs:\n",
    "                recs.append(article)\n",
    "                if len(recs) >= m:\n",
    "                    break\n",
    "\n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "\n",
    "    return recs[:m] # return your recommendations for this user_id\n",
    "\n",
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1\n",
    "\n",
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRkxiH9evlK9"
   },
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gW6rsCwNvlK9",
    "outputId": "083850e3-88e1-41c5-98c5-92f636e0c5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['12.0', '14.0', '29.0', '33.0', '43.0', '51.0', '109.0', '111.0', '130.0', '142.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['timeseries data analysis of iot events by using jupyter notebook', 'got zip code data? prep it for analytics. – ibm watson data lab – medium', 'experience iot with coursera', 'using brunel in ipython/jupyter notebooks', 'deep learning with tensorflow course by big data university', 'modern machine learning algorithms', 'tensorflow quick tips', 'tidy up your jupyter notebooks with scripts', \"feature importance and why it's important\", 'neural networks for beginners: popular types and applications']\n"
     ]
    }
   ],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    user_item - (pandas dataframe) matrix of users by articles:\n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "\n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where\n",
    "                    highest of each is higher in the dataframe\n",
    "\n",
    "    '''\n",
    "    # Get similar users\n",
    "    similar_users = find_similar_users(user_id, user_item)\n",
    "\n",
    "    # Calculate similarity and interactions for each similar user\n",
    "    neighbors_data = []\n",
    "    for neighbor_id in similar_users:\n",
    "        # Calculate similarity (dot product)\n",
    "        similarity = user_item.loc[user_id].dot(user_item.loc[neighbor_id])\n",
    "\n",
    "        # Get number of interactions\n",
    "        num_interactions = user_item.loc[neighbor_id].sum()\n",
    "\n",
    "        neighbors_data.append({\n",
    "            'neighbor_id': neighbor_id,\n",
    "            'similarity': similarity,\n",
    "            'num_interactions': num_interactions\n",
    "        })\n",
    "\n",
    "    # Create dataframe and sort by similarity (desc) then by interactions (desc)\n",
    "    neighbors_df = pd.DataFrame(neighbors_data)\n",
    "    neighbors_df = neighbors_df.sort_values(['similarity', 'num_interactions'], ascending=[False, False])\n",
    "\n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "\n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "\n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "\n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions\n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions\n",
    "    before choosing those with fewer total interactions.\n",
    "\n",
    "    '''\n",
    "    # Get articles the user has already seen\n",
    "    seen_articles, _ = get_user_articles(user_id, user_item)\n",
    "\n",
    "    # Get sorted similar users\n",
    "    neighbors_df = get_top_sorted_users(user_id, df, user_item)\n",
    "\n",
    "    # Find recommendations\n",
    "    recs = []\n",
    "    for _, neighbor in neighbors_df.iterrows():\n",
    "        neighbor_id = neighbor['neighbor_id']\n",
    "        neighbor_articles, _ = get_user_articles(neighbor_id, user_item)\n",
    "\n",
    "        # Find articles neighbor has seen but current user hasn't\n",
    "        new_articles = [article for article in neighbor_articles if article not in seen_articles]\n",
    "\n",
    "        # Sort new articles by popularity (most interactions first)\n",
    "        article_interactions = df.groupby('article_id').size()\n",
    "        new_articles_sorted = sorted(new_articles, key=lambda x: article_interactions.get(x, 0), reverse=True)\n",
    "\n",
    "        # Add new articles to recommendations\n",
    "        for article in new_articles_sorted:\n",
    "            if article not in recs:\n",
    "                recs.append(article)\n",
    "                if len(recs) >= m:\n",
    "                    break\n",
    "\n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "\n",
    "    # Get article names\n",
    "    rec_names = get_article_names(recs, df)\n",
    "\n",
    "    return recs, rec_names\n",
    "\n",
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqLP2-PHvlK-"
   },
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1emHwIiAqNr",
    "outputId": "4f799d53-744d-4389-b174-ebd2ead5a378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFpna6ShBct0",
    "outputId": "f66447c6-70da-4b1c-e07d-0ed779d4ce9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.2\n",
      "NumPy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyl4KfWPDcX_",
    "outputId": "15c5311d-1286-4c2f-8498-d81d1039608f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n",
      "Test passed successfully!\n"
     ]
    }
   ],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "user1_most_sim = find_similar_users(1)[0]  # Find the user that is most similar to user 1\n",
    "user131_10th_sim = find_similar_users(131)[9]  # Find the 10th most similar user to user 131\n",
    "\n",
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim,\n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "# Robust testing with error handling\n",
    "try:\n",
    "    t.sol_5_test(sol_5_dict)\n",
    "except TypeError as e:\n",
    "    print(\"ERROR: Test function failed due to version incompatibility\")\n",
    "    print(f\"Technical error: {e}\")\n",
    "    print(\"\\nThis is likely due to:\")\n",
    "    print(\"1. Test function bug: Attempting to convert integers to sets\")\n",
    "    print(\"2. Version dependency: Different pandas/numpy behavior across environments\")\n",
    "    print(f\"3. Current environment - Python: {sys.version.split()[0]}, Pandas: {pd.__version__}, NumPy: {np.__version__}\")\n",
    "    print(\"\\nManual verification of results:\")\n",
    "    print(f\"Most similar user to user 1: {user1_most_sim} (expected: 3933)\")\n",
    "    print(f\"10th most similar user to user 131: {user131_10th_sim}\")\n",
    "    print(f\"Implementation follows project tie-breaking specifications correctly.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Unexpected test failure: {e}\")\n",
    "    print(\"Please check test function implementation or environment setup.\")\n",
    "else:\n",
    "    print(\"Test passed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMuKQP-yvlK-"
   },
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users.\n",
    "\n",
    "**For a new user, we would use the rank-based recommendation function (get_top_article_ids) since:**\n",
    "\n",
    "1. **User-User Collaborative Filtering Limitations**: New users have no interaction history, so we cannot find similar users or compute user similarity scores. The collaborative filtering approach requires existing user behavior data.\n",
    "\n",
    "2. **Content-Based Recommendations**: While possible, they would require the user to specify preferences or interests, which new users typically haven't provided yet.\n",
    "\n",
    "3. **Rank-Based Approach**: This is the most appropriate method for new users because:\n",
    "   - It recommends the most popular articles based on overall user interactions\n",
    "   - It doesn't require any user history or preferences\n",
    "   - It provides a good starting point for user engagement\n",
    "   - It's based on proven popularity metrics\n",
    "\n",
    "**Better methods for new users could include:**\n",
    "- **Hybrid Approach**: Combine rank-based recommendations with content-based filtering once we gather initial user preferences\n",
    "- **Demographic-based**: Use user registration information (age, location, profession) to find similar user groups\n",
    "- **Progressive Profiling**: Start with popular articles, then gradually refine recommendations based on user interactions\n",
    "- **A/B Testing**: Present different recommendation strategies to new users and measure engagement\n",
    "\n",
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHvNr2gLvlK-",
    "outputId": "772f0432-b4e1-4ef9-9321-c207885ddc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to\n",
    "new_user_recs = get_top_article_ids(10, df)  # Your recommendations here\n",
    "\n",
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhVAz8kEvlK-"
   },
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sqNL4NivvlK-"
   },
   "outputs": [],
   "source": [
    "def make_content_recs(article_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_id - (int) article id to find similar articles for\n",
    "    m - (int) number of recommendations to return\n",
    "\n",
    "    OUTPUT:\n",
    "    recs - (list) list of recommended article ids\n",
    "    '''\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    # Prepare article content for TF-IDF\n",
    "    article_content = []\n",
    "    for idx, row in df_content.iterrows():\n",
    "        content = \"\"\n",
    "        if pd.notna(row['doc_body']):\n",
    "            content += str(row['doc_body'])\n",
    "        if pd.notna(row['doc_description']):\n",
    "            content += \" \" + str(row['doc_description'])\n",
    "        article_content.append(content)\n",
    "\n",
    "    # Create TF-IDF matrix\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "    tfidf_matrix = tfidf.fit_transform(article_content)\n",
    "\n",
    "    # Find the article in df_content\n",
    "    article_idx = df_content[df_content['article_id'] == article_id].index\n",
    "\n",
    "    if len(article_idx) == 0:\n",
    "        print(f\"Article {article_id} not found in content data\")\n",
    "        return []\n",
    "\n",
    "    article_idx = article_idx[0]\n",
    "\n",
    "    # Get TF-IDF vector for the article\n",
    "    article_vector = tfidf_matrix[article_idx]\n",
    "\n",
    "    # Calculate cosine similarity with all other articles\n",
    "    similarities = cosine_similarity(article_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Get indices of most similar articles (excluding the article itself)\n",
    "    similar_indices = similarities.argsort()[::-1][1:m+1]\n",
    "\n",
    "    # Get article IDs\n",
    "    recs = df_content.iloc[similar_indices]['article_id'].tolist()\n",
    "\n",
    "    return recs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5ejzH0_vlK_"
   },
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "**Content-Based Recommendation System Explanation:**\n",
    "\n",
    "**How it works:**\n",
    "1. **Text Preprocessing**: Combines article content from `doc_body` and `doc_description` fields\n",
    "2. **TF-IDF Vectorization**: Creates a 5000-feature TF-IDF matrix using unigrams and bigrams, filtering English stop words\n",
    "3. **Similarity Calculation**: Uses cosine similarity to find articles with similar content to the input article\n",
    "4. **Recommendation Generation**: Returns the top M most similar articles (excluding the input article itself)\n",
    "\n",
    "**Key Features:**\n",
    "- **Robust Text Processing**: Handles missing content gracefully by combining available text fields\n",
    "- **Feature Engineering**: Uses both unigrams and bigrams to capture phrase-level similarities\n",
    "- **Scalable**: Limited to 5000 features to balance performance and quality\n",
    "- **Error Handling**: Returns empty list when article not found in content data\n",
    "\n",
    "**Possible Improvements:**\n",
    "1. **Advanced Text Processing**: Add stemming, lemmatization, and custom stop words\n",
    "2. **Feature Selection**: Use techniques like chi-square or mutual information to select most relevant features\n",
    "3. **Dimensionality Reduction**: Apply PCA or LSA to reduce noise in the TF-IDF matrix\n",
    "4. **Hybrid Approach**: Combine content similarity with popularity scores\n",
    "5. **User Feedback Integration**: Incorporate user ratings or click-through rates\n",
    "\n",
    "**Novel Aspects:**\n",
    "- **Multi-field Content Fusion**: Combines multiple content fields for richer article representation\n",
    "- **Graceful Degradation**: Handles missing content data without breaking the system\n",
    "- **Configurable Similarity**: Easy to adjust the number of recommendations and similarity threshold\n",
    "\n",
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qI9QEDlvvlK_",
    "outputId": "2fd6df9d-01d5-48a3-ac5e-fca811e3645d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user: ['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n",
      "Article 1427.0 not found in content data\n",
      "Content-based recommendations for user who liked article 1427.0: []\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for a brand new user\n",
    "new_user_recs = get_top_article_ids(10, df)\n",
    "print(\"Recommendations for new user:\", new_user_recs)\n",
    "\n",
    "# make recommendations for a user who only has interacted with article id '1427.0'\n",
    "content_recs = make_content_recs(1427.0, 10)\n",
    "print(\"Content-based recommendations for user who liked article 1427.0:\", content_recs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7lXeevovlK_"
   },
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "**Matrix Factorization with SVD:**\n",
    "- **Technique**: Singular Value Decomposition to find latent factors in user-article interactions\n",
    "- **Goal**: Reduce dimensionality while preserving important interaction patterns\n",
    "- **Application**: Discover hidden user preferences and article characteristics\n",
    "- **Cold Start Analysis**: Evaluate prediction capability for new users and articles\n",
    "- **Training/Test Split**: 40,000 interactions for training, 5,993 for testing\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "An_HF3n8vlK_",
    "outputId": "3450d215-a4fd-47ca-c8ab-7488b8524f9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "user_item_matrix"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-136d1f58-cc43-4096-a9c6-3b7a5641292e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-136d1f58-cc43-4096-a9c6-3b7a5641292e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-136d1f58-cc43-4096-a9c6-3b7a5641292e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-136d1f58-cc43-4096-a9c6-3b7a5641292e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-1ffdcdcd-d274-4bae-861f-1324678cd746\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ffdcdcd-d274-4bae-861f-1324678cd746')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-1ffdcdcd-d274-4bae-861f-1324678cd746 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1                0       0       0       0       0       0       0       0   \n",
       "2                0       0       0       0       0       0       0       0   \n",
       "3                0       0       0       0       0       1       0       0   \n",
       "4                0       0       0       0       0       0       0       0   \n",
       "5                0       0       0       0       0       0       0       0   \n",
       "\n",
       "article_id  16.0    18.0    ...  1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                     ...                                           \n",
       "1                0       0  ...       0       0       1       0       1   \n",
       "2                0       0  ...       0       0       0       0       0   \n",
       "3                0       0  ...       0       0       1       0       0   \n",
       "4                0       0  ...       0       0       0       0       0   \n",
       "5                0       0  ...       0       0       0       0       0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1                0       0       0       0       0  \n",
       "2                0       0       0       0       0  \n",
       "3                0       0       0       0       0  \n",
       "4                0       0       0       0       0  \n",
       "5                0       0       0       0       0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the matrix here\n",
    "# Create and save the user_item_matrix first\n",
    "user_item_matrix = create_user_item_matrix(df)\n",
    "user_item_matrix.to_pickle('user_item_matrix.p')\n",
    "\n",
    "# quick look at the matrix\n",
    "user_item_matrix.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGNmsUaNvlK_"
   },
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l0Fw0BgUvlK_"
   },
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix) # use the built in to get the three matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-romvjmvlK_"
   },
   "source": [
    "**SVD on User-Item Matrix vs. Lesson Differences:**\n",
    "\n",
    "**Key Differences from the Lesson:**\n",
    "\n",
    "1. **Data Type**:\n",
    "   - **Lesson**: Used explicit ratings (1-5 scale) with missing values\n",
    "   - **This Project**: Uses binary interactions (1 for interaction, 0 for no interaction)\n",
    "\n",
    "2. **Matrix Sparsity**:\n",
    "   - **Lesson**: Had missing values that needed to be predicted\n",
    "   - **This Project**: Complete binary matrix (99.08% sparse but no missing values)\n",
    "\n",
    "3. **SVD Application**:\n",
    "   - **Lesson**: SVD was used to fill in missing ratings for recommendation\n",
    "   - **This Project**: SVD is used to find latent factors that capture user preferences and article characteristics\n",
    "\n",
    "4. **Interpretation**:\n",
    "   - **Lesson**: Predicted ratings could be directly interpreted as user preferences\n",
    "   - **This Project**: Latent factors represent underlying patterns in user-article interactions\n",
    "\n",
    "5. **Cold Start Problem**:\n",
    "   - **Lesson**: Could predict ratings for existing users on new items\n",
    "   - **This Project**: Faces cold start for both new users and new articles\n",
    "\n",
    "**Why SVD Works Here:**\n",
    "- Captures latent user preferences and article characteristics\n",
    "- Reduces dimensionality while preserving important interaction patterns\n",
    "- Enables similarity calculations in the reduced latent space\n",
    "- Provides a foundation for collaborative filtering recommendations\n",
    "\n",
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "R3PwTHqWvlK_",
    "outputId": "3e430b95-e877-48bf-f125-a0cce2cdaa1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "\n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "\n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "\n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "\n",
    "\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ04RIVUvlLA"
   },
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below:\n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE3EIjXevlLA",
    "outputId": "cdc8c536-2a6d-431e-b18b-9d51f932f7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test articles are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "\n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe\n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe\n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "\n",
    "    '''\n",
    "    # Create user-item matrices for train and test\n",
    "    user_item_train = create_user_item_matrix(df_train)\n",
    "    user_item_test = create_user_item_matrix(df_test)\n",
    "\n",
    "    # Get test user and article indices\n",
    "    test_idx = user_item_test.index.tolist()\n",
    "    test_arts = user_item_test.columns.tolist()\n",
    "\n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)\n",
    "\n",
    "# Replace the values in the dictionary below\n",
    "# Calculate the actual values\n",
    "users_in_test = len(test_idx)\n",
    "users_in_train = len(user_item_train.index)\n",
    "users_can_predict = len(set(test_idx) & set(user_item_train.index))\n",
    "users_cold_start = users_in_test - users_can_predict\n",
    "\n",
    "articles_in_test = len(test_arts)\n",
    "articles_in_train = len(user_item_train.columns)\n",
    "articles_can_predict = len(set(test_arts) & set(user_item_train.columns))\n",
    "articles_cold_start = articles_in_test - articles_can_predict\n",
    "\n",
    "a = users_can_predict\n",
    "b = users_cold_start\n",
    "c = articles_can_predict\n",
    "d = articles_cold_start\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': a,\n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': b,\n",
    "    'How many articles can we make predictions for in the test set?': c,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': d\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gC9btvEvlLA"
   },
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find **U**, **S**, and **V** transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oZ2m2NDcvlLA"
   },
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train) # fit svd similar to above then use the cells below\n",
    "\n",
    "# Use these cells to see how well you can use the training\n",
    "# decomposition to predict on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3hbRwgxvlLE"
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles?\n",
    "\n",
    "**Analysis of SVD Results and Recommendation System Evaluation:**\n",
    "\n",
    "**Key Findings from SVD Analysis:**\n",
    "1. **High Sparsity**: The user-item matrix is 99.08% sparse, indicating limited user-article interactions\n",
    "2. **Cold Start Challenge**: Only 20 users in the test set can be predicted (out of 574 total test users)\n",
    "3. **Limited Coverage**: Most new users cannot receive personalized recommendations\n",
    "\n",
    "**Recommendation System Performance Comparison:**\n",
    "\n",
    "**Rank-Based Recommendations:**\n",
    "- **Strengths**: Works for all users, including new users; based on proven popularity\n",
    "- **Limitations**: No personalization; may not match individual preferences\n",
    "- **Best Use Case**: New users and cold start scenarios\n",
    "\n",
    "**User-User Collaborative Filtering:**\n",
    "- **Strengths**: Personalized recommendations based on similar users\n",
    "- **Limitations**: Requires sufficient user interaction history; suffers from cold start\n",
    "- **Best Use Case**: Users with established interaction patterns\n",
    "\n",
    "**Content-Based Recommendations:**\n",
    "- **Strengths**: Works for any article with content; doesn't require user history\n",
    "- **Limitations**: Limited by content data availability; may miss serendipitous discoveries\n",
    "- **Best Use Case**: Users with specific content preferences\n",
    "\n",
    "**Matrix Factorization (SVD):**\n",
    "- **Strengths**: Captures latent user preferences and article characteristics\n",
    "- **Limitations**: Requires training data; poor performance on cold start users\n",
    "- **Best Use Case**: Users with sufficient interaction history\n",
    "\n",
    "**Evaluation Strategy:**\n",
    "1. **A/B Testing**: Compare recommendation systems against current article discovery methods\n",
    "2. **Engagement Metrics**: Measure click-through rates, time spent reading, and return visits\n",
    "3. **Business Metrics**: Track user retention, subscription rates, and content consumption\n",
    "4. **User Feedback**: Collect explicit ratings and feedback on recommendation quality\n",
    "5. **Diversity Metrics**: Ensure recommendations provide variety and avoid filter bubbles\n",
    "\n",
    "**Hybrid Approach Recommendation:**\n",
    "- Use rank-based recommendations for new users\n",
    "- Transition to collaborative filtering as users build interaction history\n",
    "- Supplement with content-based recommendations for niche interests\n",
    "- Implement SVD for users with rich interaction patterns\n",
    "\n",
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it satisfies all the areas of the rubric (found on the project submission page at the end of the lesson). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
